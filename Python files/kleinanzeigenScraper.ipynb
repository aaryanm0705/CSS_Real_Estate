{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "import undetected_chromedriver as uc\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import random\n",
    "import math\n",
    "import time as t\n",
    "import pandas as pd\n",
    "import re\n",
    "from deep_translator import GoogleTranslator\n",
    "from tqdm.notebook import tqdm\n",
    "from fake_useragent import UserAgent\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options \n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(A):\n",
    "    rt = []\n",
    "    for i in A:\n",
    "        if isinstance(i,list): rt.extend(flatten(i))\n",
    "        else: rt.append(i)\n",
    "    return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_number(input_string):\n",
    "    pattern = r\"\\d+\"\n",
    "    match = re.search(pattern, input_string)\n",
    "    if match:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number(input_string):\n",
    "    pattern = r\"(\\d+)\"\n",
    "    match = re.search(pattern, input_string)\n",
    "    if match:\n",
    "        extracted_number = int(match.group(1))  # Convert the matched number to an integer\n",
    "        return extracted_number\n",
    "    else:\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addressToCoord(address):\n",
    "    loc = Nominatim(user_agent=\"Geopy Library\")\n",
    "    getLoc = loc.geocode(address)\n",
    "    return(getLoc.latitude, getLoc.longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_string_in_another_string_once(main_string, sub_string):\n",
    "    index = main_string.find(sub_string)\n",
    "    if index != -1:\n",
    "        second_index = main_string.find(sub_string, index + 1)\n",
    "        if second_index == -1:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniquize(seq):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_only_numbers(input_string):\n",
    "    pattern = r\"^\\d+$\"\n",
    "    return bool(re.match(pattern, input_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = UserAgent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mother_url = 'https://www.kleinanzeigen.de'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apartments = 'https://www.kleinanzeigen.de/s-wohnung-mieten/c203'\n",
    "houses = 'https://www.kleinanzeigen.de/s-haus-mieten/c205'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pagination Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {'User-Agent':str(ua.random)}\n",
    "content = requests.get(apartments, headers = header)\n",
    "soup = BeautifulSoup(content.content, 'html.parser')\n",
    "\n",
    "cities_container = soup.find_all('ul', {'class':'treelist browsebox-itemlist is-root'})[-1]\n",
    "cities_container_narrow = cities_container.find_all('li')\n",
    "cities_apartments = [mother_url + i.find('a', {'href':True})['href'] for i in cities_container_narrow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {'User-Agent':str(ua.random)}\n",
    "content = requests.get(houses, headers = header)\n",
    "soup = BeautifulSoup(content.content, 'html.parser')\n",
    "\n",
    "cities_container = soup.find_all('ul', {'class':'treelist browsebox-itemlist is-root'})[-1]\n",
    "cities_container_narrow = cities_container.find_all('li')\n",
    "cities_houses = [mother_url + i.find('a', {'href':True})['href'] for i in cities_container_narrow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pages_apartments = []\n",
    "for city in tqdm(cities_apartments):\n",
    "    link = city.split('/')\n",
    "    link[-1:-1] = ['seite:50']\n",
    "    link_last = '/'.join(link)\n",
    "\n",
    "    header = {'User-Agent':str(ua.random)}\n",
    "    content = requests.get(link_last, headers = header)\n",
    "    \n",
    "    true_last = content.url\n",
    "    true_last_number = extract_number(true_last.split('/')[-2])\n",
    "    pages = [true_last.replace(str(true_last_number), str(i)) for i in range(1, true_last_number + 1)]\n",
    "    \n",
    "    all_pages_apartments.append(pages)\n",
    "\n",
    "all_pages_apartments = flatten(all_pages_apartments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pages_houses = []\n",
    "for city in tqdm(cities_houses):\n",
    "    link = city.split('/')\n",
    "    link[-1:-1] = ['seite:50']\n",
    "    link_last = '/'.join(link)\n",
    "\n",
    "    header = {'User-Agent':str(ua.random)}\n",
    "    content = requests.get(link_last, headers = header)\n",
    "    \n",
    "    true_last = content.url\n",
    "    true_last_number = extract_number(true_last.split('/')[-2])\n",
    "    pages = [true_last.replace(str(true_last_number), str(i)) for i in range(1, true_last_number + 1)]\n",
    "    \n",
    "    all_pages_houses.append(pages)\n",
    "\n",
    "all_pages_houses = flatten(all_pages_houses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_products_apartments = []\n",
    "\n",
    "for page in tqdm(all_pages_apartments):\n",
    "    header = {'User-Agent':str(ua.random)}\n",
    "    content = requests.get(page, headers = header)\n",
    "    soup = BeautifulSoup(content.content, 'html.parser')\n",
    "\n",
    "    product_container = soup.find('ul', {'class':'itemlist ad-list it3'})\n",
    "    if product_container is not None:\n",
    "        product_container_narrow = product_container.find_all('li', {'class':'ad-listitem'})\n",
    "        products_raw = [i.find('article', {'class':'aditem'}) for i in product_container_narrow]\n",
    "\n",
    "        all_products = []\n",
    "        for i in products_raw:\n",
    "            if i != None:\n",
    "                products = mother_url + i.find('a', {'href':True})['href']\n",
    "                all_products.append(products)\n",
    "            else:\n",
    "                continue\n",
    "        all_products_apartments.append(all_products)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "all_products_apartments = uniquize(flatten(all_products_apartments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_products_houses = []\n",
    "\n",
    "for page in tqdm(all_pages_houses):\n",
    "    header = {'User-Agent':str(ua.random)}\n",
    "    content = requests.get(page, headers = header)\n",
    "    soup = BeautifulSoup(content.content, 'html.parser')\n",
    "\n",
    "    product_container = soup.find('ul', {'class':'itemlist ad-list it3'})\n",
    "    if product_container is not None:\n",
    "        product_container_narrow = product_container.find_all('li', {'class':'ad-listitem'})\n",
    "        products_raw = [i.find('article', {'class':'aditem'}) for i in product_container_narrow]\n",
    "\n",
    "        all_products = []\n",
    "        for i in products_raw:\n",
    "            if i != None:\n",
    "                products = mother_url + i.find('a', {'href':True})['href']\n",
    "                all_products.append(products)\n",
    "            else:\n",
    "                continue\n",
    "        all_products_houses.append(all_products)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "all_products_houses = uniquize(flatten(all_products_houses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf5af4e051648aca905063859914ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12804.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# all_sizes = []\n",
    "# all_links1 = []\n",
    "# all_rooms1 = []\n",
    "# all_final_costs1 = []\n",
    "# all_zip_codes1 = []\n",
    "# all_latitudes1 = []\n",
    "# all_longitudes1 = []\n",
    "# all_floors1 = []\n",
    "# all_balconies = []\n",
    "# all_storages = []\n",
    "# all_elevators = []\n",
    "\n",
    "\n",
    "for link in tqdm(all_products_apartments[1349+3637+45+349:]):\n",
    "    header = {'User-Agent':str(ua.random)}\n",
    "    content = requests.get(link, headers = header)\n",
    "    soup = BeautifulSoup(content.content, 'html.parser')\n",
    "    \n",
    "    test_price = soup.find('h2', {'class':'boxedarticle--price'})\n",
    "    if test_price:\n",
    "        price_raw = test_price.text.strip().replace('€', '').replace('.', '').replace(',', '.')\n",
    "        if has_number(price_raw):\n",
    "            price = float(test_price.text.strip().replace('€', '').replace('.', '').replace(',', '.').replace('  VB', ''))\n",
    "        else:\n",
    "            price = None\n",
    "    else:\n",
    "        price = None\n",
    "\n",
    "    test_address = soup.find('div', {'itemprop':'address'})\n",
    "    if test_address:\n",
    "        address_container = test_address.find_all('span')\n",
    "        address_raw = [i.text.strip().replace(',', '') for i in address_container]\n",
    "        address_raw = flatten([i.split() for i in address_raw])\n",
    "\n",
    "        zip_code = None\n",
    "        for i in address_raw:\n",
    "            if contains_only_numbers(i) and len(i) == 5:\n",
    "                zip_code = int(i)\n",
    "            else:\n",
    "                continue\n",
    "        try:\n",
    "            latlong = addressToCoord(' '.join(address_raw))\n",
    "        except:\n",
    "            latlong = None\n",
    "\n",
    "        if latlong != None:    \n",
    "            latitude = float(latlong[0])\n",
    "            longitude = float(latlong[1])\n",
    "        else:\n",
    "            latitude = None\n",
    "            longitude = None\n",
    "    else:\n",
    "        latitude = None\n",
    "        longitude = None\n",
    "        zip_code = None\n",
    "        \n",
    "    test_info = soup.find('ul', {'class':'addetailslist'})\n",
    "    if test_info:\n",
    "        info_container = test_info.find_all('li', {'class':'addetailslist--detail'})\n",
    "        info_raw = [i.text.replace('\\n                                       ', '').strip().lower() for i in info_container]\n",
    "\n",
    "        interior_size = None\n",
    "        rooms = None\n",
    "        floor = None\n",
    "        for component in info_raw:\n",
    "            if 'wohnfläche' in component:\n",
    "                interior_size = float(component.replace('wohnfläche ', '').replace(' m²', '').replace('.', '').replace(',', '.'))\n",
    "            elif 'zimmer' in component and 'bade' not in component and 'schlaf' not in component and 'ess' not in component and 'privat' not in component and 'kinder' not in component:\n",
    "                rooms = float(component.replace('zimmer ', '').replace('.', '').replace(',', '.'))\n",
    "            elif 'etage' in component and 'wohnung' not in component or 'etagen' in component and 'etagenwohnung' not in component:\n",
    "                floor = int(component.replace('etage ', '').replace('etagen ', ''))\n",
    "            else:\n",
    "                continue\n",
    "    else:\n",
    "        rooms = None\n",
    "        interior_size = None\n",
    "        floor = None\n",
    "\n",
    "    test_additionals = soup.find('ul', {'class':'checktaglist'})\n",
    "    if test_additionals:\n",
    "        additionals_container = test_additionals.find_all('li', {'class':'checktag'})\n",
    "        additionals_raw = [i.text.strip().lower() for i in additionals_container]\n",
    "\n",
    "        balcony = 0\n",
    "        storage = 0\n",
    "        elevator = 0\n",
    "        for i in additionals_raw:\n",
    "            if 'balkon' in i or 'terrasse' in i:\n",
    "                balcony = 1\n",
    "            elif 'keller' in i:\n",
    "                storage = 1\n",
    "            elif 'aufzug' in i:\n",
    "                elevator = 1\n",
    "            else:\n",
    "                continue\n",
    "    else:\n",
    "        balcony = 0\n",
    "        storage = 0\n",
    "        elevator = 0\n",
    "                \n",
    "    all_sizes.append(interior_size)\n",
    "    all_rooms1.append(rooms)\n",
    "    all_final_costs1.append(price)\n",
    "    all_zip_codes1.append(zip_code)\n",
    "    all_latitudes1.append(latitude)\n",
    "    all_longitudes1.append(longitude)\n",
    "    all_floors1.append(floor)\n",
    "    all_balconies.append(balcony)\n",
    "    all_storages.append(storage)\n",
    "    all_elevators.append(elevator)\n",
    "    all_links1.append(link)\n",
    "    \n",
    "all_sizes = flatten(all_sizes)\n",
    "all_rooms1 = flatten(all_rooms1)\n",
    "all_final_costs1 = flatten(all_final_costs1)\n",
    "all_zip_codes1 = flatten(all_zip_codes1)\n",
    "all_latitudes1 = flatten(all_latitudes1)\n",
    "all_longitudes1 = flatten(all_longitudes1)\n",
    "all_floors1 = flatten(all_floors1)\n",
    "all_balconies = flatten(all_balconies)\n",
    "all_storages = flatten(all_storages)\n",
    "all_elevators = flatten(all_elevators)\n",
    "all_links1 = flatten(all_links1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c4b116268a4a579df2bff5423cf6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4569.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_interior_sizes = []\n",
    "all_exterior_sizes = []\n",
    "all_links2 = []\n",
    "all_rooms2 = []\n",
    "all_final_costs2 = []\n",
    "all_zip_codes2 = []\n",
    "all_latitudes2 = []\n",
    "all_longitudes2 = []\n",
    "all_floors2 = []\n",
    "all_parkings = []\n",
    "all_house_types = []\n",
    "all_terraces = []\n",
    "all_years = []\n",
    "\n",
    "for link in tqdm(all_products_houses):\n",
    "    header = {'User-Agent':str(ua.random)}\n",
    "    content = requests.get(link, headers = header)\n",
    "    soup = BeautifulSoup(content.content, 'html.parser')\n",
    "    \n",
    "    test_price = soup.find('h2', {'class':'boxedarticle--price'})\n",
    "    if test_price:\n",
    "        price_raw = test_price.text.strip().replace('€', '').replace('.', '').replace(',', '.')\n",
    "        if has_number(price_raw):\n",
    "            price = float(test_price.text.strip().replace('€', '').replace('.', '').replace(',', '.').replace('  VB', ''))\n",
    "        else:\n",
    "            price = None\n",
    "    else:\n",
    "        price = None\n",
    "\n",
    "    test_address = soup.find('div', {'itemprop':'address'})\n",
    "    if test_address:\n",
    "        address_container = test_address.find_all('span')\n",
    "        address_raw = [i.text.strip().replace(',', '') for i in address_container]\n",
    "        address_raw = flatten([i.split() for i in address_raw])\n",
    "\n",
    "        zip_code = None\n",
    "        for i in address_raw:\n",
    "            if contains_only_numbers(i) and len(i) == 5:\n",
    "                zip_code = int(i)\n",
    "            else:\n",
    "                continue\n",
    "        try:\n",
    "            latlong = addressToCoord(' '.join(address_raw))\n",
    "        except:\n",
    "            latlong = None\n",
    "\n",
    "        if latlong != None:    \n",
    "            latitude = float(latlong[0])\n",
    "            longitude = float(latlong[1])\n",
    "        else:\n",
    "            latitude = None\n",
    "            longitude = None\n",
    "    else:\n",
    "        latitude = None\n",
    "        longitude = None\n",
    "        zip_code = None\n",
    "\n",
    "    test_info = soup.find('ul', {'class':'addetailslist'})\n",
    "    if test_info:\n",
    "        info_container = test_info.find_all('li', {'class':'addetailslist--detail'})\n",
    "        info_raw = [i.text.replace('\\n                                       ', '').strip().lower() for i in info_container]\n",
    "\n",
    "        interior_size = None\n",
    "        exterior_size = None\n",
    "        rooms = None\n",
    "        floor = None\n",
    "        house_type = None\n",
    "        year = None\n",
    "        for component in info_raw:\n",
    "            if 'wohnfläche' in component and 'grund' not in component:\n",
    "                interior_size = float(component.replace('wohnfläche ', '').replace(' m²', '').replace('.', '').replace(',', '.'))\n",
    "            elif 'zimmer' in component and 'bade' not in component and 'schlaf' not in component  and 'ess' not in component:\n",
    "                rooms = float(component.replace('zimmer ', '').replace('.', '').replace(',', '.'))\n",
    "            elif 'grundstücksfläche' in component and 'wohn' not in component:\n",
    "                exterior_size = float(component.replace('grundstücksfläche ', '').replace(' m²', '').replace('.', '').replace(',', '.'))    \n",
    "            elif 'etagen' in component and 'wohnung' not in component:\n",
    "                floor = int(component.replace('etagen ', ''))\n",
    "            elif 'haustyp' in component:\n",
    "                house_type = GoogleTranslator(source='de', target='en').translate(component.replace('haustyp ', '')).lower()\n",
    "            elif 'baujahr' in component:\n",
    "                year = int(component.replace('baujahr ', ''))\n",
    "            else:\n",
    "                continue\n",
    "    else:\n",
    "        rooms = None\n",
    "        interior_size = None\n",
    "        exterior_size = None\n",
    "        floor = None\n",
    "        house_type = None\n",
    "        year = None\n",
    "\n",
    "    test_additionals = soup.find('ul', {'class':'checktaglist'})\n",
    "    if test_additionals:\n",
    "        additionals_container = test_additionals.find_all('li', {'class':'checktag'})\n",
    "        additionals_raw = [i.text.strip().lower() for i in additionals_container]\n",
    "\n",
    "        terrace = 0\n",
    "        parking = 0\n",
    "        for i in additionals_raw:\n",
    "            if 'balkon' in i or 'terrasse' in i:\n",
    "                terrace = 1\n",
    "            elif 'garage' in i or 'stellplatz' in i:\n",
    "                parking = 1\n",
    "            else:\n",
    "                continue\n",
    "    else:\n",
    "        terrace = 0\n",
    "        parking = 0\n",
    "                \n",
    "    all_interior_sizes.append(interior_size)\n",
    "    all_exterior_sizes.append(exterior_size)\n",
    "    all_rooms2.append(rooms)\n",
    "    all_final_costs2.append(price)\n",
    "    all_zip_codes2.append(zip_code)\n",
    "    all_latitudes2.append(latitude)\n",
    "    all_longitudes2.append(longitude)\n",
    "    all_floors2.append(floor)\n",
    "    all_links2.append(link)\n",
    "    all_parkings.append(parking)\n",
    "    all_house_types.append(house_type)\n",
    "    all_terraces.append(terrace)\n",
    "    all_years.append(year)\n",
    "    \n",
    "all_interior_sizes = flatten(all_interior_sizes)\n",
    "all_exterior_sizes = flatten(all_exterior_sizes)\n",
    "all_rooms2 = flatten(all_rooms2)\n",
    "all_final_costs2 = flatten(all_final_costs2)\n",
    "all_zip_codes2 = flatten(all_zip_codes2)\n",
    "all_latitudes2 = flatten(all_latitudes2)\n",
    "all_longitudes2 = flatten(all_longitudes2)\n",
    "all_floors2 = flatten(all_floors2)\n",
    "all_house_types = flatten(all_house_types)\n",
    "all_parkings = flatten(all_parkings)\n",
    "all_links2 = flatten(all_links2)\n",
    "all_terraces = flatten(all_terraces)\n",
    "all_years = flatten(all_years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_apartments = pd.DataFrame()\n",
    "data_houses = pd.DataFrame()\n",
    "\n",
    "data_apartments['Link'] = all_links1\n",
    "data_apartments['Interior Size'] = all_sizes\n",
    "data_apartments['Room Count'] = all_rooms1\n",
    "data_apartments['Zip Code'] = all_zip_codes1\n",
    "data_apartments['Latitude'] = all_latitudes1\n",
    "data_apartments['Longitude'] = all_longitudes1\n",
    "data_apartments['Floor Level'] = all_floors1\n",
    "data_apartments['Balcony'] = all_balconies\n",
    "data_apartments['Storage'] = all_storages\n",
    "data_apartments['Elevator'] = all_elevators\n",
    "data_apartments['Price'] = all_final_costs1\n",
    "data_apartments['Zip Code'] = data_apartments['Zip Code'].fillna(0).astype(int).replace(0, None)\n",
    "\n",
    "data_houses['Link'] = all_links2\n",
    "data_houses['House Type'] = all_house_types\n",
    "data_houses['Year Constructed'] = all_years\n",
    "data_houses['Interior Size'] = all_interior_sizes\n",
    "data_houses['Exterior Size'] = all_exterior_sizes\n",
    "data_houses['Room Count'] = all_rooms2\n",
    "data_houses['Zip Code'] = all_zip_codes2\n",
    "data_houses['Latitude'] = all_latitudes2\n",
    "data_houses['Longitude'] = all_longitudes2\n",
    "data_houses['Floor Count'] = all_floors2\n",
    "data_houses['Parking'] = all_parkings\n",
    "data_houses['Terrace'] = all_terraces\n",
    "data_houses['Price'] = all_final_costs2\n",
    "data_houses['Zip Code'] = data_houses['Zip Code'].fillna(0).astype(int).replace(0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_value(value):\n",
    "    if value >= 1000 and value <= 9999:\n",
    "        return f'0{value:04}'\n",
    "    return str(value)\n",
    "\n",
    "data_apartments['Zip Code'] = data_apartments['Zip Code'].apply(format_value)\n",
    "data_houses['Zip Code'] = data_houses['Zip Code'].apply(format_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_apartments.to_excel('kleineinzeigenApartments.xlsx', index=False, engine='openpyxl')\n",
    "data_houses.to_excel('kleineinzeigenHouses.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_apartments = pd.read_excel('kleineinzeigenApartments.xlsx', engine='openpyxl', dtype={'Zip Code': str})\n",
    "data_houses = pd.read_excel('kleineinzeigenHouses.xlsx', engine='openpyxl', dtype={'Zip Code': str})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
